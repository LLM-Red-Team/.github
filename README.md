# LLM Red Team

如果您看到了这个组织，请允许我为您介绍它：

LLM Red Team 意为 LLM大模型红队，大模型应用发展速度超乎了所有人的预料，在这样得表象下是日益严重的安全风险。

本组织成立的原意是通过各厂商大模型应用中已公开的信息挖掘潜在的安全问题，期间可能会公开一些技术细节，如果影响到您应用的正常运营请联系组织负责人，我们会及时下线相关仓库。

<font color="red">**所有内容仅供研究禁止套壳对外服务对官方造成服务压力！！**</font>

以下是我们目前已公开的仓库：

Moonshot AI (Kimi.ai) 接口转API [kimi-free-api](https://github.com/LLM-Red-Team/kimi-free-api)

阿里通义 (Qwen) 接口转API [qwen-free-api](https://github.com/LLM-Red-Team/qwen-free-api)

ZhipuAI (智谱清言) 接口转API [glm-free-api](https://github.com/LLM-Red-Team/glm-free-api)

聆心智能 (Emohaa) 接口转API [emohaa-free-api](https://github.com/LLM-Red-Team/emohaa-free-api)
